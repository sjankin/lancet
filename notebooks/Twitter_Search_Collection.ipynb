{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select language using one of the following codes:\n",
    "- en (English, default option)\n",
    "- de (German)\n",
    "- es (Spanish)\n",
    "- fr (French)\n",
    "- pt (Portuguese)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_ref = { 'en' : { 'name' : 'English', 'batch_size' : 50000},\n",
    "                 'de' : { 'name' : 'German', 'batch_size' : 10000},\n",
    "                 'es' : { 'name' : 'Spanish', 'batch_size' : 50000},\n",
    "                 'fr' : { 'name' : 'French', 'batch_size' : 25000},\n",
    "                 'pt' : { 'name' : 'Portuguese', 'batch_size' : 10000},\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "keywords_file = os.path.join(\"..\", \"keywords\", language + \".json\")\n",
    "\n",
    "climate_dict = []\n",
    "health_dict = []\n",
    "compound_terms = []\n",
    "\n",
    "def normalise_keywords(dict): #lowercases and handles compounds\n",
    "    for i in range(0, len(dict)):\n",
    "        keyword = dict[i].lower()\n",
    "        compound = keyword.replace(' ','_')\n",
    "        if compound != keyword:\n",
    "            keyword = compound\n",
    "            words = tuple(compound.split('_'))\n",
    "            compound_terms.append(words)\n",
    "        dict[i] = keyword\n",
    "    return dict\n",
    "\n",
    "with open(keywords_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "climate_dict= normalise_keywords(data['climate'])\n",
    "health_dict = normalise_keywords(data['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malaria',\n",
       " 'diarrhoea',\n",
       " 'infection',\n",
       " 'disease',\n",
       " 'sars',\n",
       " 'measles',\n",
       " 'pneumonia',\n",
       " 'epidemic',\n",
       " 'pandemic',\n",
       " 'public_health',\n",
       " 'healthcare',\n",
       " 'epidemiology',\n",
       " 'health_care',\n",
       " 'health',\n",
       " 'mortality',\n",
       " 'morbidity',\n",
       " 'nutrition',\n",
       " 'illness',\n",
       " 'infectious',\n",
       " 'ncd',\n",
       " 'non-communicable_disease',\n",
       " 'noncommunicable_disease',\n",
       " 'communicable_disease',\n",
       " 'air_pollution',\n",
       " 'nutrition',\n",
       " 'malnutrition',\n",
       " 'mental_disorder',\n",
       " 'stunting']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['climate_change',\n",
       " 'global_warming',\n",
       " 'green_house',\n",
       " 'temperature',\n",
       " 'extreme_weather',\n",
       " 'global_environmental_change',\n",
       " 'climate_variability',\n",
       " 'greenhouse',\n",
       " 'low_carbon',\n",
       " 'ghge',\n",
       " 'renewable_energy',\n",
       " 'carbon_emission',\n",
       " 'co2_emission',\n",
       " 'climate_pollutant']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_credentials = \"twitter_credentials.json\"\n",
    "\n",
    "tweets_folder = os.path.join(\"..\", \"data\", \"tweets\", language)\n",
    "tweets_climate_filename_prefix = \"tweets_climate.\" + language + \".\"\n",
    "tweets_health_filename_prefix = \"tweets_health.\" + language + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterSearch import *\n",
    "\n",
    "with open(twitter_credentials) as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "def get_tweets(keywords, dump):\n",
    "    try:\n",
    "        tso = TwitterSearchOrder()\n",
    "        tso.set_keywords(keywords, or_operator = True)\n",
    "        tso.set_language(language)\n",
    "        tso.set_include_entities(True)\n",
    "\n",
    "        ts = TwitterSearch(\n",
    "            consumer_key = credentials[\"consumer_key\"],\n",
    "            consumer_secret = credentials[\"consumer_secret\"],\n",
    "            access_token = credentials[\"access_token\"],\n",
    "            access_token_secret = credentials[\"access_token_secret\"]\n",
    "        )\n",
    "\n",
    "        for tweet in ts.search_tweets_iterable(tso):\n",
    "            dump[tweet['id']] = tweet\n",
    "\n",
    "    except TwitterSearchException as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def store_tweets(tweets, filename):\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        fieldnames = ['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'extended_entities', \n",
    "                      'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', \n",
    "                      'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', \n",
    "                      'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', \n",
    "                      'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang', \n",
    "                      'quoted_status_id', 'quoted_status_id_str', 'quoted_status', 'withheld_in_countries']\n",
    "        w = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "        w.writerows(tweets.values())\n",
    "\n",
    "def load_tweets(filename):\n",
    "    tweets = {}\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            tweets[row['id']] = row\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "batch_threshold = language_ref[language][\"batch_size\"]\n",
    "iterations = 10\n",
    "\n",
    "for i in range(1, iterations):\n",
    "    current_tweets_climate = {}\n",
    "    current_tweets_health = {}\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "    print(timestamp)\n",
    "    \n",
    "    tweets_climate_filename = os.path.join(tweets_folder, tweets_climate_filename_prefix + timestamp + \".csv\")\n",
    "    tweets_health_filename = os.path.join(tweets_folder, tweets_health_filename_prefix + timestamp + \".csv\")\n",
    "\n",
    "    while len(current_tweets_health) < batch_threshold:\n",
    "        get_tweets(climate_dict, current_tweets_climate)\n",
    "        get_tweets(health_dict, current_tweets_health)\n",
    "        time.sleep(600)\n",
    "\n",
    "    store_tweets(current_tweets_climate, tweets_climate_filename)\n",
    "    store_tweets(current_tweets_health, tweets_health_filename)\n",
    "    print(\"Climate tweets: %d - Health tweets: %d\" % (len(current_tweets_climate), len(current_tweets_health)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "tweets_climate = {}\n",
    "tweets_health = {}\n",
    "\n",
    "files = listdir(tweets_folder)\n",
    "for f in files:\n",
    "    if tweets_health_filename_prefix in f:\n",
    "        print(\"Loading %s\" % f)\n",
    "        for (tweet_id, tweet) in load_tweets(os.path.join(tweets_folder, f)).items():\n",
    "            tweets_health[tweet_id] = tweet\n",
    "    if tweets_climate_filename_prefix in f:\n",
    "        print(\"Loading %s\" % f)\n",
    "        for (tweet_id, tweet) in load_tweets(os.path.join(tweets_folder, f)).items():\n",
    "            tweets_climate[tweet_id] = tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Climate tweets: %d - Health tweets: %d\" % (len(tweets_climate), len(tweets_health)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
